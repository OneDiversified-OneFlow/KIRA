"""
Confluence Page Summarizer Agent

Analyzes multiple Confluence page updates to extract and summarize only important information.
"""

import logging
import os
from typing import Any, Dict, List, Optional

from claude_agent_sdk import (
    ClaudeAgentOptions,
    ClaudeSDKClient,
    ResultMessage,
)


async def save_to_memory(content: str) -> None:
    """
    Adds Confluence page update content to memory queue.

    Args:
        content: Content to save (important page update summary)
    """
    try:
        from app.queueing_extended import enqueue_memory_job

        memory_query = f"""The following are recent Confluence page updates. Save if there is useful information.

{content}

Use the `slack-memory-store` skill to categorize and save this information appropriately.
Always save items related to team members.
"""

        # Add job to memory queue (processed sequentially)
        await enqueue_memory_job({
            "memory_query": memory_query
        })
        logging.info(f"[CONFLUENCE_SUMMARIZER] Memory job enqueued")
    except Exception as e:
        logging.error(f"[CONFLUENCE_SUMMARIZER] Memory enqueue failed: {e}")


def create_system_prompt(state_prompt: str, bot_name: str, bot_role: str = "") -> str:
    """Create system prompt for Confluence summarizer

    Args:
        state_prompt: Current state prompt generated by create_state_prompt()
        bot_name: Bot name
        bot_role: Bot's role in the company

    Returns:
        str: System prompt including agent behavior and tool usage principles
    """
    # Role section (only if configured)
    role_section = ""
    if bot_role:
        role_section = f"""

## Role in the Company
<bot_role>
{bot_role}
Prioritize saving information related to this role.
</bot_role>"""

    system_prompt = f"""You are {bot_name}, a virtual resident employee who communicates via Slack.

# Basic Instructions
You are an agent that analyzes Confluence page updates and extracts only important information.
You receive multiple Confluence page updates and filter and organize **only business-critical content**.
The key is to organize and deliver only important page updates so that successor agents can reference them in subsequent conversations.
{role_section}

{state_prompt}

## Workflow
<workflow>
1. Analyze the batch of Confluence page updates received.
2. If necessary, use Rovo MCP tools to query the full page content.
3. Evaluate the importance of each page according to the criteria.
4. Select and organize only important page updates.
</workflow>

## Tool Usage Principles
<how_to_use_tool>
1. First use the `confluence-deep-reader` skill, then use Rovo MCP tools according to the workflow.
2. If importance cannot be determined from title and modification info alone, always query the page content for accurate evaluation.
3. Use page ID to pass the correct ID when calling tools.
4. Only query page content when importance is unclear to improve efficiency.
5. If you need to create files, always create them temporarily in `FILESYSTEM_BASE_DIR/checkers/tmp/` directory, and delete after completion.
</how_to_use_tool>

## Core Action Principles
<important_actions>
**Criteria for Important Page Updates:**
- Team member related matters
- Project plans, schedules, milestone changes
- Technical documents, API specifications, architecture changes
- Meeting notes, decision records
- Policy, guideline, process changes
- Team announcements, important issue tracking
</important_actions>

## Output Format
<output_format>
When there are important page updates:
- Organize update content in detail, categorized by type.
- Include each page's title, URL, modifier, modification time, and key changes.

When there are no important page updates:
- Output only "No important page updates."
</output_format>

## Guardrail Policy
<guardrails>
**Filtered Out Items:**
- Personal notes and temporary work pages are not important.
- Do not save minor typo fixes or format changes.
- Exclude test pages.
- Exclude duplicate/repeated content.

**File System Access Restriction:**
- Never access files or directories outside FILESYSTEM_BASE_DIR
- Reading or modifying system files, home directory, config files, etc. is strictly prohibited
- File operations must be limited to within FILESYSTEM_BASE_DIR
</guardrails>"""

    return system_prompt


async def call_confluence_summarizer(
    pages: List[Dict[str, Any]]
) -> Optional[str]:
    """
    Analyzes batch of Confluence pages and summarizes only important content.

    Args:
        pages: Page list (including id, title, version, spaceId)

    Returns:
        Optional[str]: Query for memory storage (None if no important content)
    """
    if not pages:
        return None

    # Get settings and bot_name first
    from app.cc_agents.state_prompt import create_state_prompt
    from app.config.settings import get_settings

    settings = get_settings()
    bot_name = settings.BOT_NAME or "Bot"
    bot_role = settings.BOT_ROLE or ""

    # Create state_prompt (without slack_data, message_data)
    state_prompt = create_state_prompt()

    system_prompt = create_system_prompt(state_prompt, bot_name, bot_role)

    # Convert page list to text
    pages_text = ""
    for idx, page in enumerate(pages, 1):
        page_id = page.get("id", "")
        title = page.get("title", "")
        version = page.get("version", {})
        modified_date = version.get("createdAt", "")
        modified_by_id = version.get("authorId", "Unknown")
        modified_by_email = version.get("authorEmail", "")
        space_id = page.get("spaceId", "")
        page_url = f"{settings.ATLASSIAN_CONFLUENCE_SITE_URL}/wiki/spaces/{space_id}/pages/{page_id}"

        # Display modifier (email preferred, ID if not available)
        modified_by = modified_by_email if modified_by_email else modified_by_id

        pages_text += f"""
Page {idx}:
Page ID: {page_id}
Title: {title}
URL: {page_url}
Modified by: {modified_by}
Modified time: {modified_date}

---
"""

    user_query = f"""Analyze the following {len(pages)} Confluence page updates:

{pages_text}

Make sure not to omit any matters related to team members."""

    # Atlassian MCP server settings (remote)
    mcp_servers = {
        "atlassian": {
            "command": "npx",
            "args": ["mcp-cache", "npx", "-y", "mcp-remote", "https://mcp.atlassian.com/v1/sse"]
        }
    }

    options = ClaudeAgentOptions(
        system_prompt=system_prompt,
        model=settings.MODEL_FOR_SIMPLE,
        permission_mode="bypassPermissions",
        allowed_tools=["*"],
        disallowed_tools=[
            "Bash(curl:*)",
            "Bash(rm:*)",
            "Bash(rm -r*)",
            "Bash(rm -rf*)",
            "Read(./.env)",
            "Read(./credential.json)",
            "WebFetch",
            "Write",
            "Edit",
            "NotebookEdit",
        ],
        setting_sources=['project'],
        cwd=os.getcwd(),
        mcp_servers=mcp_servers,
    )

    session_id = None
    result_message = ""

    # Retry with /compact after context overflow (maintain same client, max 2 retries)
    max_retries = 2

    async with ClaudeSDKClient(options=options) as client:
        for attempt in range(max_retries + 1):
            try:
                # First attempt is new session, retries continue compacted session
                if session_id:
                    await client.query(user_query, session_id)
                else:
                    await client.query(user_query)

                async for message in client.receive_response():
                    if hasattr(message, 'subtype') and message.subtype == 'init':
                        session_id = message.data.get('session_id')
                        logging.info(f"[CONFLUENCE_SUMMARIZER] Session ID: {session_id}")

                    if isinstance(message, ResultMessage):
                        if "API Error" in message.result and "413" in message.result:
                            raise Exception(f"Context overflow in ResultMessage: {message.result}")

                        result_message = message.result.strip()
                        logging.info(f"[CONFLUENCE_SUMMARIZER] Result: {result_message[:100]}...")
                        break

                # Exit loop on success
                break

            except Exception as e:
                error_str = str(e)
                error_msg = error_str.lower()

                is_context_error = any([
                    "prompt is too long" in error_msg,
                    "context overflow" in error_msg,
                    "413" in error_msg,
                ])

                if is_context_error and attempt < max_retries:
                    logging.warning(f"[CONFLUENCE_SUMMARIZER] Context overflow detected (attempt {attempt + 1}/{max_retries}), executing /compact...")

                    # Execute /compact with same client (pass session_id)
                    await client.query("/compact", session_id)
                    async for msg in client.receive_response():
                        if isinstance(msg, ResultMessage):
                            logging.info(f"[CONFLUENCE_SUMMARIZER] /compact executed successfully")
                            break

                    # Retry with same client and original query
                    continue
                else:
                    # Max retries exceeded or other error
                    logging.error(f"[CONFLUENCE_SUMMARIZER] Error occurred: {e}")
                    return None

    # Return result after loop completes normally
    if result_message == "No important page updates." or not result_message:
        logging.info("[CONFLUENCE_SUMMARIZER] No important pages found")
        return None

    return result_message
